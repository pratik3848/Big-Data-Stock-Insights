{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d4614d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/17 20:31:22 INFO org.apache.spark.SparkEnv: Registering MapOutputTracker\n",
      "23/03/17 20:31:22 INFO org.apache.spark.SparkEnv: Registering BlockManagerMaster\n",
      "23/03/17 20:31:22 INFO org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "23/03/17 20:31:22 INFO org.apache.spark.SparkEnv: Registering OutputCommitCoordinator\n",
      "23/03/17 20:31:36 WARN org.apache.spark.sql.execution.window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/03/17 20:31:36 WARN org.apache.spark.sql.execution.window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+--------------------+------+\n",
      "|asset_class|   code|         description|locale|\n",
      "+-----------+-------+--------------------+------+\n",
      "|     stocks|     CS|        Common Stock|    us|\n",
      "|     stocks|    PFD|     Preferred Stock|    us|\n",
      "|     stocks|WARRANT|             Warrant|    us|\n",
      "|     stocks|  RIGHT|              Rights|    us|\n",
      "|     stocks|   BOND|      Corporate Bond|    us|\n",
      "|     stocks|    ETF|Exchange Traded Fund|    us|\n",
      "|     stocks|    ETN|Exchange Traded Note|    us|\n",
      "|     stocks|    ETV|Exchange Traded V...|    us|\n",
      "|     stocks|     SP|  Structured Product|    us|\n",
      "|     stocks|   ADRC|American Deposito...|    us|\n",
      "|     stocks|   ADRP|American Deposito...|    us|\n",
      "|     stocks|   ADRW|American Deposito...|    us|\n",
      "|     stocks|   ADRR|American Deposito...|    us|\n",
      "|     stocks|   FUND|                Fund|    us|\n",
      "|     stocks| BASKET|              Basket|    us|\n",
      "|     stocks|   UNIT|                Unit|    us|\n",
      "|     stocks|     LT|   Liquidating Trust|    us|\n",
      "|     stocks|     OS|     Ordinary Shares|    us|\n",
      "|     stocks|    GDR|Global Depository...|    us|\n",
      "|     stocks|  OTHER| Other Security Type|    us|\n",
      "+-----------+-------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n",
      "root\n",
      " |-- asset_class: string (nullable = true)\n",
      " |-- code: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- locale: string (nullable = true)\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/17 20:31:36 WARN org.apache.spark.sql.execution.window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/03/17 20:31:36 WARN org.apache.spark.sql.execution.window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import (StructType, StructField, StringType,\n",
    "                               IntegerType, BooleanType, TimestampType,\n",
    "                              ArrayType, MapType, DateType)\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "spark = SparkSession \\\n",
    "        .builder.appName(\"DimTickerTypes\") \\\n",
    "        .config(\"spark.jars.packages\", \"com.google.cloud.spark:spark-bigquery-with-dependencies_2.12:0.24.0\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "#load types DF\n",
    "types_df = spark \\\n",
    "        .read.option(\"recursiveFileLookup\", \"true\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .parquet(\"gs://stocks-pipeline/raw-data/ticker_types\")\n",
    "\n",
    "\n",
    "print(types_df.show())\n",
    "\n",
    "print(types_df.printSchema())\n",
    "    \n",
    "\n",
    "types_df = types_df.withColumn(\"TypeKey\", f.row_number().over(Window.orderBy('code')))\n",
    "\n",
    "types_df = types_df.withColumnRenamed(\"code\",\"TypeCode\") \\\n",
    "            .withColumnRenamed(\"description\", \"Description\") \\\n",
    "            .withColumnRenamed(\"locale\", \"Locale\")\n",
    "            \n",
    "\n",
    "types_df = types_df.fillna(value = 'Not Available', subset = [\"Description\"])\n",
    "types_df= types_df.drop(\"asset_class\")\n",
    "# persist_df = types_df.persist()\n",
    "\n",
    "# print(persist_df.show())\n",
    "    \n",
    " # create a BigQuery client and dataset reference\n",
    "client = bigquery.Client(project='noted-span-377814')\n",
    "dataset_ref = client.dataset('Stocks_DW')\n",
    "\n",
    "# create a BigQuery table and upload the data\n",
    "table_ref = dataset_ref.table('DimTickerTypes')\n",
    "job_config = bigquery.LoadJobConfig(write_disposition='WRITE_APPEND')\n",
    "job = client.load_table_from_dataframe(types_df.toPandas(), table_ref, job_config=job_config)\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b9c3c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}